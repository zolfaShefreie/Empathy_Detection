{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install lightning","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:55:10.307167Z","iopub.execute_input":"2023-05-06T06:55:10.308282Z","iopub.status.idle":"2023-05-06T06:55:20.596456Z","shell.execute_reply.started":"2023-05-06T06:55:10.308237Z","shell.execute_reply":"2023-05-06T06:55:20.595196Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Requirement already satisfied: lightning in /opt/conda/lib/python3.7/site-packages (1.9.5)\nRequirement already satisfied: starlette<2.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.22.0)\nRequirement already satisfied: torch<4.0,>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.13.0)\nRequirement already satisfied: croniter<1.4.0,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.3.14)\nRequirement already satisfied: dateutils<2.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.6.12)\nRequirement already satisfied: traitlets<7.0,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (5.8.1)\nRequirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (2023.1.0)\nRequirement already satisfied: psutil<7.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (5.9.3)\nRequirement already satisfied: websockets<12.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (11.0)\nRequirement already satisfied: requests<4.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (2.28.2)\nRequirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.21.6)\nRequirement already satisfied: lightning-cloud>=0.5.27 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.5.34)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from lightning) (23.0)\nRequirement already satisfied: websocket-client<3.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.4.2)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (4.64.1)\nRequirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.7/site-packages (from lightning) (6.0)\nRequirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (4.11.1)\nRequirement already satisfied: lightning-utilities<2.0,>=0.6.0.post0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.8.0)\nRequirement already satisfied: torchmetrics<2.0,>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.11.4)\nRequirement already satisfied: pydantic<3.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.10.4)\nRequirement already satisfied: inquirer<5.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (2.10.1)\nRequirement already satisfied: arrow<3.0,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.2.3)\nRequirement already satisfied: fastapi<0.89.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.88.0)\nRequirement already satisfied: uvicorn<2.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.20.0)\nRequirement already satisfied: click<10.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (8.1.3)\nRequirement already satisfied: typing-extensions<6.0,>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (4.4.0)\nRequirement already satisfied: deepdiff<8.0,>=5.7.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (6.3.0)\nRequirement already satisfied: Jinja2<5.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (3.1.2)\nRequirement already satisfied: starsessions<2.0,>=1.2.1 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.3.0)\nRequirement already satisfied: rich<15.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (13.2.0)\nRequirement already satisfied: urllib3<3.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.26.14)\nRequirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.7/site-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.3.2.post1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<10.0->lightning) (4.11.4)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from dateutils<2.0->lightning) (2023.3)\nRequirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /opt/conda/lib/python3.7/site-packages (from deepdiff<8.0,>=5.7.0->lightning) (4.1.0)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from starlette<2.0->lightning) (3.6.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.7/site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.3)\nRequirement already satisfied: blessed>=1.19.0 in /opt/conda/lib/python3.7/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.19.1)\nRequirement already satisfied: python-editor>=1.0.4 in /opt/conda/lib/python3.7/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.0.4)\nRequirement already satisfied: readchar>=3.0.6 in /opt/conda/lib/python3.7/site-packages (from inquirer<5.0,>=2.10.0->lightning) (4.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2<5.0->lightning) (2.1.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from lightning-cloud>=0.5.27->lightning) (1.16.0)\nRequirement already satisfied: python-multipart in /opt/conda/lib/python3.7/site-packages (from lightning-cloud>=0.5.27->lightning) (0.0.6)\nRequirement already satisfied: pyjwt in /opt/conda/lib/python3.7/site-packages (from lightning-cloud>=0.5.27->lightning) (2.6.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<4.0->lightning) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<4.0->lightning) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<4.0->lightning) (2.1.1)\nRequirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from rich<15.0->lightning) (2.1.0)\nRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from rich<15.0->lightning) (2.14.0)\nRequirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.7/site-packages (from uvicorn<2.0->lightning) (0.14.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.1)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (0.13.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (22.2.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.8.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.3)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.7/site-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning) (1.3.0)\nRequirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.7/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click<10.0->lightning) (3.11.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.7/site-packages (from markdown-it-py<3.0.0,>=2.1.0->rich<15.0->lightning) (0.1.2)\nRequirement already satisfied: setuptools>=41.0 in /opt/conda/lib/python3.7/site-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning) (59.8.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:55:31.030448Z","iopub.execute_input":"2023-05-06T06:55:31.030906Z","iopub.status.idle":"2023-05-06T06:55:40.932625Z","shell.execute_reply.started":"2023-05-06T06:55:31.030854Z","shell.execute_reply":"2023-05-06T06:55:40.931356Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.27.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torchmetrics","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:55:40.936429Z","iopub.execute_input":"2023-05-06T06:55:40.936877Z","iopub.status.idle":"2023-05-06T06:55:51.044906Z","shell.execute_reply.started":"2023-05-06T06:55:40.936831Z","shell.execute_reply":"2023-05-06T06:55:51.043656Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.7/site-packages (0.11.4)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (1.21.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (23.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (4.4.0)\nRequirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (1.13.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torchtext\nimport numpy as np\nimport pandas as pd\nimport torch\nimport lightning.pytorch as pl\nfrom lightning.pytorch.callbacks.early_stopping import EarlyStopping\nfrom lightning.pytorch.callbacks import ModelCheckpoint, Callback\nfrom torchmetrics import Accuracy, F1Score\nimport torchmetrics\nimport matplotlib.pyplot as plt ","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:55:51.047702Z","iopub.execute_input":"2023-05-06T06:55:51.048473Z","iopub.status.idle":"2023-05-06T06:55:51.057428Z","shell.execute_reply.started":"2023-05-06T06:55:51.048428Z","shell.execute_reply":"2023-05-06T06:55:51.056401Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# utils","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:55:51.061377Z","iopub.execute_input":"2023-05-06T06:55:51.061681Z","iopub.status.idle":"2023-05-06T06:55:51.067848Z","shell.execute_reply.started":"2023-05-06T06:55:51.061652Z","shell.execute_reply":"2023-05-06T06:55:51.066784Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"## dataset","metadata":{}},{"cell_type":"code","source":"class EmpathyConversationDataset(Dataset):\n    \n\n    FILE_PATH = {'train': \"/kaggle/input/dialogue-empathy-detection/train.csv\",\n                 'test': \"/kaggle/input/dialogue-empathy-detection/test.csv\",\n                 'val': \"/kaggle/input/dialogue-empathy-detection/val.csv\",}\n\n    def __init__(self, split=\"train\", transforms=None):\n\n        if split.lower() not in self.FILE_PATH.keys():\n            raise Exception(\"must be train or test or val\")\n\n        df = pd.read_csv(self.FILE_PATH[split.lower()])\n        df = self.conv_preprocess(df)\n        \n        self.x = df[['utterance']].to_numpy()\n        self.y = df[['empathy']].to_numpy()\n        self.n_sample = len(df)\n\n        self.transforms = transforms\n    \n    def conv_preprocess(self, df):\n        return df.groupby('conv_id')['utterance'].apply(list).reset_index().\\\n                  merge(df.groupby('conv_id')['empathy'].max().reset_index(), on='conv_id', how=\"inner\")\n\n    def __getitem__(self, index):\n        sample = self.x[index], self.y[index]\n        return self._pipline_transforms(sample)\n    \n    def _pipline_transforms(self, sample):\n        if self.transforms:\n            for transform in self.transforms:\n                sample = transform(sample)\n        return sample\n    \n    def __len__(self):\n        return self.n_sample","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:55:51.069511Z","iopub.execute_input":"2023-05-06T06:55:51.070082Z","iopub.status.idle":"2023-05-06T06:55:51.084299Z","shell.execute_reply.started":"2023-05-06T06:55:51.070044Z","shell.execute_reply":"2023-05-06T06:55:51.083182Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"class TextListCleaner:\n\n    punc = '''!()-[]{.};:'\"\\,<>/?@#$%^&*_~`|’“”…—–'''\n\n    def __call__(self, sample):\n        texts, target = sample\n        texts = texts[0]\n        new_texts = list()\n        \n        for text in texts:\n            text = text.lower()\n            for each in self.punc:\n                text = text.replace(each, ' ')\n            new_texts.append(text)\n        return np.array([new_texts]), target\n\n\nclass ConversationFormater:\n    SPECIAL_TOKEN_START_UTTERANCE = \"<BOU>\"\n    SPECIAL_TOKEN_END_UTTERANCE = \"<EOU>\"  \n    \n    def __call__(self, sample):\n        texts, target = sample\n        texts = texts[0]\n        \n        conversation = str()\n        for text in texts:\n            conversation += f\"{self.SPECIAL_TOKEN_START_UTTERANCE} {text} {self.SPECIAL_TOKEN_END_UTTERANCE} \"\n        return np.array([conversation]), target\n\n    \nclass Tokenizer:\n\n    def __init__(self, version=\"bert-base-uncased\", max_len=128, tokenizer=None, new_special_tokens=None):\n        self.tokenizer = AutoTokenizer.from_pretrained(version) if tokenizer is None else tokenizer\n        \n        if new_special_tokens:\n            tokenizer.add_special_tokens(new_special_tokens)\n            \n        self.MAX_LEN = max_len\n\n    def __call__(self, sample):\n        text, target = sample\n        inputs = self.tokenizer.encode_plus(text[0], add_special_tokens=True, max_length=self.MAX_LEN, padding='max_length', \n                                             return_attention_mask=True, return_token_type_ids=True, truncation=True)\n        return inputs['input_ids'], inputs['attention_mask'], inputs['token_type_ids'], target\n\n\nclass ToTensor:\n    # Convert ndarrays to Tensors\n    def __call__(self, sample):\n        return tuple(torch.from_numpy(np.array(each)) for each in sample)\n    \n\nclass OneHotLabel:\n    \n    def __init__(self, num_classes):\n        self.num_classes = num_classes\n    \n    def __call__(self, sample):\n        target = sample[-1]\n        target = torch.squeeze(torch.nn.functional.one_hot(target, num_classes=self.num_classes), dim=0)\n        sample = list(sample[:-1]) + [target]\n        return tuple(sample)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:55:51.087026Z","iopub.execute_input":"2023-05-06T06:55:51.087729Z","iopub.status.idle":"2023-05-06T06:55:51.102032Z","shell.execute_reply.started":"2023-05-06T06:55:51.087621Z","shell.execute_reply":"2023-05-06T06:55:51.100868Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class HistoryCallback(Callback):\n\n    def __init__(self):\n        super().__init__()\n        self.metrics = []\n\n    def on_validation_end(self, trainer, pl_module):\n        self.metrics.append({key: value.item() for key, value in trainer.callback_metrics.items()})","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:55:55.108717Z","iopub.execute_input":"2023-05-06T06:55:55.109183Z","iopub.status.idle":"2023-05-06T06:55:55.116474Z","shell.execute_reply.started":"2023-05-06T06:55:55.109144Z","shell.execute_reply":"2023-05-06T06:55:55.114995Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"# DiagGPT","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:55:57.744909Z","iopub.execute_input":"2023-05-06T06:55:57.745515Z","iopub.status.idle":"2023-05-06T06:55:58.021708Z","shell.execute_reply.started":"2023-05-06T06:55:57.745477Z","shell.execute_reply":"2023-05-06T06:55:58.020649Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"pip_trans = [TextListCleaner(), \n             ConversationFormater(),\n             Tokenizer(tokenizer=tokenizer, new_special_tokens={'additional_special_tokens': [ConversationFormater.SPECIAL_TOKEN_START_UTTERANCE,\n                                                                                              ConversationFormater.SPECIAL_TOKEN_END_UTTERANCE],\n                                                               'pad_token': '[PAD]'},\n                        max_len=512),\n             ToTensor()]","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:56:00.951709Z","iopub.execute_input":"2023-05-06T06:56:00.952423Z","iopub.status.idle":"2023-05-06T06:56:00.958071Z","shell.execute_reply.started":"2023-05-06T06:56:00.952383Z","shell.execute_reply":"2023-05-06T06:56:00.956868Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"tokenizer.all_special_tokens","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:56:03.177974Z","iopub.execute_input":"2023-05-06T06:56:03.178354Z","iopub.status.idle":"2023-05-06T06:56:03.185259Z","shell.execute_reply.started":"2023-05-06T06:56:03.178319Z","shell.execute_reply":"2023-05-06T06:56:03.184177Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"['<|endoftext|>', '[PAD]', '<BOU>', '<EOU>']"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = EmpathyConversationDataset(transforms=pip_trans)\ntest_dataset = EmpathyConversationDataset(split=\"test\", transforms=pip_trans)\nval_dataset = EmpathyConversationDataset(split=\"val\", transforms=pip_trans)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:56:04.866098Z","iopub.execute_input":"2023-05-06T06:56:04.866474Z","iopub.status.idle":"2023-05-06T06:56:05.056280Z","shell.execute_reply.started":"2023-05-06T06:56:04.866440Z","shell.execute_reply":"2023-05-06T06:56:05.055200Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:42:34.249088Z","iopub.execute_input":"2023-05-06T06:42:34.249444Z","iopub.status.idle":"2023-05-06T06:42:34.293649Z","shell.execute_reply.started":"2023-05-06T06:42:34.249407Z","shell.execute_reply":"2023-05-06T06:42:34.292750Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(tensor([50257,  1312,   285,  1760,  2282,  1312,  1842,   345,   284,   607,\n           780,  1312,   836,   256,   765,   284,  3285,   257,  6486,   736,\n           284,   502,   220,  1312,  1254,   523, 13400,   290, 19125,   290,\n          9642,  2668,   220, 50258,   220, 50257,  4686,    74,   644,   257,\n          2266,  9582,  1724,  3446,   475,   616,  5608,   284,   345,   318,\n           611,   673, 13622,   345,   826,   788,  5089,   607,   612,   389,\n         13188,   286,   584,  4813,   503,   612,   220,   290,   611,   334,\n          1254,   588,   287,  1842,   351,   607,   290,   655,  2666,   607,\n           788,  1949,   284,   407,  1337,   290,   345,   423,   284,  2453,\n           262,  1109,   326,   617,  4813,   355,   880,   355,   617,  3730,\n           220,   481,  6486,  3892,   284,   534,  1986,   329,   812,  1231,\n           597, 34081,   220,   616,  5608,   318,  2245, 18088,   878,  1165,\n          2739,   220,   220, 50258,   220, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n         50259, 50259]),\n tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]),\n tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]),\n tensor([0]))"},"metadata":{}}]},{"cell_type":"code","source":"train_dataloader = DataLoader(dataset=train_dataset, batch_size=4, shuffle=True)\ntest_dataloader = DataLoader(dataset=test_dataset, batch_size=4)\nval_dataloader = DataLoader(dataset=val_dataset, batch_size=4)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:56:09.825200Z","iopub.execute_input":"2023-05-06T06:56:09.826411Z","iopub.status.idle":"2023-05-06T06:56:09.850778Z","shell.execute_reply.started":"2023-05-06T06:56:09.826360Z","shell.execute_reply":"2023-05-06T06:56:09.849600Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoConfig\nAutoConfig.from_pretrained('microsoft/DialoGPT-small')","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:56:11.416651Z","iopub.execute_input":"2023-05-06T06:56:11.417551Z","iopub.status.idle":"2023-05-06T06:56:11.524592Z","shell.execute_reply.started":"2023-05-06T06:56:11.417512Z","shell.execute_reply":"2023-05-06T06:56:11.523455Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"GPT2Config {\n  \"_name_or_path\": \"microsoft/DialoGPT-small\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"GPT2LMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 50256,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 50256,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"gpt2\",\n  \"n_ctx\": 1024,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_inner\": null,\n  \"n_layer\": 12,\n  \"n_positions\": 1024,\n  \"reorder_and_upcast_attn\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attn_by_inverse_layer_idx\": false,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"conversational\": {\n      \"max_length\": 1000\n    }\n  },\n  \"transformers_version\": \"4.27.4\",\n  \"use_cache\": true,\n  \"vocab_size\": 50257\n}"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModel\nfrom transformers import AutoConfig\n\n\nclass EmpathyDetectionDialoGPTModel(pl.LightningModule):\n    \n    LOSS = torch.nn.BCEWithLogitsLoss()\n    \n    def __init__(self, embedding_tokens_len=None, config=AutoConfig.from_pretrained('microsoft/DialoGPT-small')):\n        super().__init__()\n        self.transformer_model = AutoModel.from_config(config)\n        if embedding_tokens_len:\n            # when transformer_model.wte.weight.shape[0] != len(tokenizer)\n            self.transformer_model.resize_token_embeddings(embedding_tokens_len)\n        self.drop = torch.nn.Dropout(0.5)\n        self.out = torch.nn.Linear(768, 1)\n\n    def forward(self, ids, mask, token_type_ids):\n        x = self.transformer_model(ids, attention_mask=mask, token_type_ids=token_type_ids)[0].mean(dim=1)\n        x = self.drop(x)\n        output = self.out(x)\n        return output\n    \n    def training_step(self, batch, batch_idx):\n        ids, mask, token_type_ids, y = batch\n        pred = self(ids, mask, token_type_ids)\n        loss = self.LOSS(pred, y.float())\n        acc = torchmetrics.functional.classification.binary_accuracy(pred, y.float())\n        self.log_dict({\"train_loss\": loss, \"train_accuracy\": acc},on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        ids, mask, token_type_ids, y = batch\n        pred = self(ids, mask, token_type_ids)\n        val_loss = self.LOSS(pred, y.float())\n        acc = torchmetrics.functional.classification.binary_accuracy(pred, y.float())\n        self.log_dict({\"val_loss\": val_loss, \"val_accuracy\": acc}, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        return val_loss\n    \n    def test_step(self, batch, batch_idx):\n        ids, mask, token_type_ids, y = batch\n        pred = self(ids, mask, token_type_ids)\n        test_loss = self.LOSS(pred, y.float())\n        acc = torchmetrics.functional.classification.binary_accuracy(pred, y.float())\n        f1_score = torchmetrics.functional.f1_score(pred, y.float(), task=\"binary\")\n        self.log_dict({\"test_loss\": test_loss, \"test_accuracy\": acc, \"test_f1\": f1_score}, \n                      on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        return test_loss\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=5e-5)\n        return optimizer","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:56:19.187832Z","iopub.execute_input":"2023-05-06T06:56:19.188213Z","iopub.status.idle":"2023-05-06T06:56:19.283274Z","shell.execute_reply.started":"2023-05-06T06:56:19.188180Z","shell.execute_reply":"2023-05-06T06:56:19.282228Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"config = AutoConfig.from_pretrained('microsoft/DialoGPT-small', n_positions=512)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:56:21.906960Z","iopub.execute_input":"2023-05-06T06:56:21.908022Z","iopub.status.idle":"2023-05-06T06:56:21.992792Z","shell.execute_reply.started":"2023-05-06T06:56:21.907981Z","shell.execute_reply":"2023-05-06T06:56:21.991871Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"model = EmpathyDetectionDialoGPTModel(embedding_tokens_len=len(tokenizer), config=config)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:56:23.825167Z","iopub.execute_input":"2023-05-06T06:56:23.825925Z","iopub.status.idle":"2023-05-06T06:56:26.967220Z","shell.execute_reply.started":"2023-05-06T06:56:23.825886Z","shell.execute_reply":"2023-05-06T06:56:26.966135Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = ModelCheckpoint(\n    save_top_k=1,\n    monitor=\"val_loss\",\n    mode=\"min\",\n    dirpath=\"./dialoGPT\",\n    filename=\"dialoGPT-empathy-conv-{epoch:02d}-{val_loss:.2f}\",\n)\nearly_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\nhistory_callback = HistoryCallback()\ntrainer = pl.Trainer(limit_train_batches=100, max_epochs=50, callbacks=[history_callback, early_stop, model_checkpoint], \n                     accelerator='auto', devices=2)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:56:26.968904Z","iopub.execute_input":"2023-05-06T06:56:26.969499Z","iopub.status.idle":"2023-05-06T06:56:26.992761Z","shell.execute_reply.started":"2023-05-06T06:56:26.969461Z","shell.execute_reply":"2023-05-06T06:56:26.991874Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"INFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: IPU available: False, using: 0 IPUs\nINFO: HPU available: False, using: 0 HPUs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.fit(model=model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:56:30.305096Z","iopub.execute_input":"2023-05-06T06:56:30.305503Z","iopub.status.idle":"2023-05-06T07:07:30.870455Z","shell.execute_reply.started":"2023-05-06T06:56:30.305465Z","shell.execute_reply":"2023-05-06T07:07:30.869057Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"INFO: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\nINFO: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\nINFO: ----------------------------------------------------------------------------------------------------\ndistributed_backend=nccl\nAll distributed processes registered. Starting with 2 processes\n----------------------------------------------------------------------------------------------------\n\n/opt/conda/lib/python3.7/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /kaggle/working/dialoGPT exists and is not empty.\n  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nINFO: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\nINFO: \n  | Name              | Type      | Params\n------------------------------------------------\n0 | transformer_model | GPT2Model | 124 M \n1 | drop              | Dropout   | 0     \n2 | out               | Linear    | 769   \n------------------------------------------------\n124 M     Trainable params\n0         Non-trainable params\n124 M     Total params\n496.199   Total estimated model params size (MB)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:218: UserWarning: strategy=ddp_spawn and num_workers=0 may result in data loading bottlenecks. Consider setting num_workers>0 and persistent_workers=True\n  \"strategy=ddp_spawn and num_workers=0 may result in data loading bottlenecks.\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"947e4356ca97418f9a590b5431353005"}},"metadata":{}},{"name":"stderr","text":"[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"# history_df = pd.DataFrame(history_callback.metrics)\n# history_df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T07:07:30.872968Z","iopub.execute_input":"2023-05-06T07:07:30.873288Z","iopub.status.idle":"2023-05-06T07:07:30.881010Z","shell.execute_reply.started":"2023-05-06T07:07:30.873254Z","shell.execute_reply":"2023-05-06T07:07:30.879885Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# plt.plot(history_df.train_accuracy)\n# plt.plot(history_df.val_accuracy)\n# plt.title('model accuracy')\n# plt.ylabel('accuracy')\n# plt.xlabel('epoch')\n# plt.legend(['Train', 'Validation'], loc='upper left')","metadata":{"execution":{"iopub.status.busy":"2023-05-06T07:07:30.882791Z","iopub.execute_input":"2023-05-06T07:07:30.883347Z","iopub.status.idle":"2023-05-06T07:07:30.892205Z","shell.execute_reply.started":"2023-05-06T07:07:30.883299Z","shell.execute_reply":"2023-05-06T07:07:30.891223Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# plt.plot(history_df.train_loss)\n# plt.plot(history_df.val_loss)\n# plt.title('model loss')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['Train', 'Validation'], loc='upper left')","metadata":{"execution":{"iopub.status.busy":"2023-05-06T07:07:30.896332Z","iopub.execute_input":"2023-05-06T07:07:30.896636Z","iopub.status.idle":"2023-05-06T07:07:30.906301Z","shell.execute_reply.started":"2023-05-06T07:07:30.896605Z","shell.execute_reply":"2023-05-06T07:07:30.905374Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"trainer.test(model, dataloaders=test_dataloader, ckpt_path='best')","metadata":{"execution":{"iopub.status.busy":"2023-05-06T07:07:30.909012Z","iopub.execute_input":"2023-05-06T07:07:30.909857Z","iopub.status.idle":"2023-05-06T07:07:54.205672Z","shell.execute_reply.started":"2023-05-06T07:07:30.909788Z","shell.execute_reply":"2023-05-06T07:07:54.204518Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"INFO: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\nINFO: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\nINFO: ----------------------------------------------------------------------------------------------------\ndistributed_backend=nccl\nAll distributed processes registered. Starting with 2 processes\n----------------------------------------------------------------------------------------------------\n\nINFO: Restoring states from the checkpoint path at /kaggle/working/dialoGPT/dialoGPT-empathy-conv-epoch=04-val_loss=0.60.ckpt\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nINFO: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\nINFO: Loaded model weights from checkpoint at /kaggle/working/dialoGPT/dialoGPT-empathy-conv-epoch=04-val_loss=0.60.ckpt\n/opt/conda/lib/python3.7/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:320: PossibleUserWarning: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n  category=PossibleUserWarning,\n/opt/conda/lib/python3.7/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:218: UserWarning: strategy=ddp_spawn and num_workers=0 may result in data loading bottlenecks. Consider setting num_workers>0 and persistent_workers=True\n  \"strategy=ddp_spawn and num_workers=0 may result in data loading bottlenecks.\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5686c8fa4c945e5a9fa7b5ee6768b41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m   test_accuracy_epoch   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6926829218864441    \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m      test_f1_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7867595553398132    \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m     test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6181172728538513    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">    test_accuracy_epoch    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6926829218864441     </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">       test_f1_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7867595553398132     </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">      test_loss_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6181172728538513     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"},"metadata":{}},{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"[{'test_loss_epoch': 0.6181172728538513,\n  'test_accuracy_epoch': 0.6926829218864441,\n  'test_f1_epoch': 0.7867595553398132}]"},"metadata":{}}]}]}
